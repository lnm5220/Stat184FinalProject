---
title: "Stat 184 Final Project"
author: "Leah Miller"
date: "Due December 16, 2019"
output:
  html_notebook: default
  pdf_document: default
---

***
# Set up
### Clean up environment & load packages
```{r}
rm(list = ls())
library(rvest)
library(tidyverse)
library(lubridate)
library(knitr)
library(ggplot2)
library(DataComputing)
library(data.table)
library(tidyr)
library(dplyr)
```
***


# The Data
### I chose to use data regarding healthcare. The first dataset is insurance costs from different Americans. The second dataset is google searches of health conditions.
- Here I read in the CSV Files:

```{r}
insuranceData = read.csv("insurance.csv")
googleData = read.csv("RegionalInterestByConditionOverTime.csv")
```

### Exploratory Data Analysis of insurance data
- First, I will explore the insurance data. I start this process by viewing the first 6 records:

```{r}
head(insuranceData, 6)
```

- Next I will plot some graphs to see the trends within insurance data:

```{r}
costbyRegion <- ggplot(insuranceData, aes(x = region, y = charges)) +
  geom_boxplot() +
  geom_boxplot(fill = "#5DADE2", alpha = .7) +
  labs(title = "Charges by Region",
              caption = "This plot shows total medical costs billed by health insurance for each region.") +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(hjust = 0))

costbyRegion
```


```{r} 
facetCosts <- ggplot(data=insuranceData,aes(x=age,y=charges))+
  geom_point()+
  aes(colour=smoker)+
  scale_color_manual(values=c("#AED6F1" , "#21618C"))+
  scale_x_log10()+
  facet_wrap(~region,ncol=4)+
  labs(title = "Charges VS Age (Regional)",
              caption = "This plot shows how charges vary in each region depending on the age of the beneficiary and whether or not they smoke.")+
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(hjust = 0))

facetCosts
```


- Next I will explore the google data. I will simply start by viewing the data table:

```{r}
head(googleData,6)
```
 
# Data Cleaning
- I quickly realized that this data was formatted in a way that is not useful. Before I begin to explore the data further using plots, first I must extract the most recent search data (2017).

```{r}
CleanGoogleData <-
  googleData %>% 
  select(dma, geoCode, X2017.cancer, X2017.cardiovascular, X2017.depression, X2017.stroke, X2017.rehab, X2017.vaccine, X2017.obesity, X2017.diarrhea)

```

- Next I will use regular expressions to extract the State Abbreviation from the location. Then I use mutate to apply the regular expression to all of the addresses. At this point I also drop the "geoCode" column because it is not needed.

```{r}
address <- "Philadelphia PA"

stateAbbr <- str_extract(address, "\\b[A-Z]{2}")

CleanGoogleData <- CleanGoogleData %>% 
  select(-geoCode) %>% 
  mutate(dma = str_extract(dma, "\\b[A-Z]{2}"))

head(CleanGoogleData, 6)
```

- Our data is almost clean. Since all of this data is from 2017 I am going to reformat year into its own column. I also drop the "X2017." at the beginning of each of the conditions.

```{r}
gatheredData <- melt(CleanGoogleData, id.vars = "dma", variable = 'condition')
gatheredData <- gatheredData %>% 
  mutate(year = '2017') %>% 
  mutate(condition = gsub('X2017.','',condition))

head(gatheredData, 6)
```
- Now I will group by state so I can do analysis on a state level.

- *Note* at this point I realized population may have an effect on searches. I decided to upload a CSV file with state populations so I could find a standarized number of searches based on state population. This new column is called "SearchesPer" and is the number of searches per 100,000 people.

```{r}
populationData = read.csv("population.csv")

StateGoogleData <-
  gatheredData %>% 
  group_by(dma, condition) %>% 
  summarise (total = sum(value))

StateGoogleData <- setnames(StateGoogleData, "dma", "State")


PopulationGoogleData <- merge(StateGoogleData, populationData, by = 'State', type = "full", match = "all")

PopulationGoogleData <- 
  PopulationGoogleData %>% 
  mutate(searchesPer = total/Population *100000)

head(PopulationGoogleData, 6)
```

- Next, I group by region. This is to make the comparison to the insurance data easier because it is also grouped by region.

- *Note* There are only 4 regions included in Insurance data due to what was surveyed in the study. Due to this, I will only be including those regions for the google data so the comparison is equal. This excludes certain states like Alaska who are in the far north region. They will be labeled with an NA and then ommitted from the dataset.

```{r}
southwest <- c('AZ','CA','NM','NV','OK','TX')
southeast <- c('AL','AR','DE','FL','GA','KY','LA','MD','DC','MS','MC','SC')
northwest <- c('CA', 'CO', 'ID', 'MT', 'ND', 'NE', 'NV', 'OR', 'SD', 'UT', 'WA', 'WY')
northeast <- c('CT','IA','IL','IN','KS','MA','ME','MI','MN','MO','NH','NJ','NY','OH','PA','RI','SD','VA','VT','WI', 'WV')

RegionalGoogleData <-
  PopulationGoogleData %>% 
  mutate(region = ifelse(State %in% southwest, "southwest",
                                     ifelse(State %in% southeast, "southeast",
                                            ifelse(State %in% northwest, "northwest",
                                                   ifelse(State %in% northeast, "northeast", NA)))))

RegionalGoogleData <- na.omit(RegionalGoogleData)
head(RegionalGoogleData)
```

# Exploratory Analysis of Google data
- Here is some analysis of the 2017 google data.

```{r}
StateSearches <- 
  ggplot(data = RegionalGoogleData, aes(x= condition, y= State)) +
  geom_tile(aes(fill=searchesPer)) +
  scale_fill_gradient2(low='white',mid='#5DADE2',high='black',midpoint=20) + 
  labs(title ="Searches by State (Per 100,000)",x = "Condition", y = "State", fill="Total Searches")+
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(hjust = 0))

StateSearches

RegionSearches <-
  ggplot(data=RegionalGoogleData,aes(x=condition,y=searchesPer,order=reorder(condition,searchesPer),fill=condition))+
  geom_bar(stat='identity',position='stack', width=.9)+
  scale_fill_brewer(type='seq',palette=1)+
  facet_wrap(~region,ncol=2)+
  labs(title = "Searches by Region (Per 100,000)",
       caption = "This plot shows the variation in number of searches for each region and each condition.")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(hjust = 0))

RegionSearches
```

# Joining the two tables
- Quickly clean up both data frames by grouping by region and then joining the two tables.

```{r}
RegionalGoogleData <-
  RegionalGoogleData %>% 
  group_by(region, condition) %>% 
  summarise(total_searches = mean(searchesPer))
  
head(RegionalGoogleData)

insuranceData <-
  insuranceData %>% 
  group_by(region) %>% 
  summarise(total_charges = mean(charges))

head(insuranceData)
```

```{R}
JoinedTable <- merge(RegionalGoogleData, insuranceData, by = 'region', type = "full", match = "all")

head(JoinedTable)
```
























