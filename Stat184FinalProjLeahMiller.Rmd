---
title: "Stat 184 Final Project"
author: "Leah Miller"
date: "Due December 16, 2019"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---


## Set up
### Clean up environment & load packages
```{r}
rm(list = ls())
library(rvest)
library(tidyverse)
library(lubridate)
library(knitr)
library(ggplot2)
library(DataComputing)
library(data.table)
```

## Import The Data
- I chose to use data regarding healthcare. The first dataset is insurance costs from different Americans. The second dataset is google searches of health conditions.

```{r}
insuranceData = read.csv("insurance.csv")
googleData = read.csv("RegionalInterestByConditionOverTime.csv")
```


## Exploratory Data Analysis
- First, I will explore the insurance data. I start this process by viewing the first 6 records.
```{r}
head(insuranceData, 6)
```

- Next I will plot some graphs to see the trends within insurance data.

```{r}
costbyRegion <- ggplot(insuranceData, aes(x = region, y = charges)) +
  geom_boxplot() + geom_boxplot(fill = "#4271AE", alpha = .7) + theme_bw()

costbyRegion
```


```{r} 
facetCosts <- ggplot(data=insuranceData,aes(x=age,y=charges))+geom_point()+aes(colour=smoker)+scale_x_log10()+facet_wrap(~region,ncol=4) 
### add captions

facetCosts
```


- Next I will explore the google data. I will simply start by viewing the data table.

```{r}
head(googleData,6)
```
 
 ## Data Cleaning
- I quickly realized that this data was formatted in a way that is not useful. Before I begin to explore the data further using plots, first I must extract the most recent search data (2017).

```{r}
CleanGoogleData <-
  googleData %>% 
  select(dma, geoCode, X2017.cancer, X2017.cardiovascular, X2017.depression, X2017.stroke, X2017.rehab, X2017.vaccine, X2017.obesity, X2017.diarrhea)

```


- Next I will use regular expressions to extract the State Abbreviation from the location. Then I use mutate to apply the regular expression to all of the addresses. At this point I also drop the "geoCode" column because it is not needed.

```{r}
address <- "Philadelphia PA"

stateAbbr <- str_extract(address, "\\b[A-Z]{2}")

CleanGoogleData <- CleanGoogleData %>% 
  select(-geoCode) %>% 
  mutate(dma = str_extract(dma, "\\b[A-Z]{2}"))

head(CleanGoogleData, 6)
```


- Our data is almost clean. Since all of this data is from 2017 I am going to reformat year into its own column. Then, I will add a column called "region" to the google data. This will be useful when comparing this data to the insurance data which is also grouped by region.

```{r}
gatheredData <- melt(CleanGoogleData, id.vars = "dma", variable = 'condition')
gatheredData <- gatheredData %>% 
  mutate(year = '2017') %>% 
  mutate(condition = gsub('X2017.','',condition))

head(gatheredData, 6)
```
- Now I will group by state so I can do analysis on a state level. Then, I will add a column called "region" to the google data. This will be useful when comparing this data to the insurance data which is also grouped by region.

```{r}
StateGoogleData <-
  gatheredData %>% 
  group_by(dma, condition) %>% 
  summarise (total = sum(value))

head(StateGoogleData, 6)
```

- *Note* There are only 4 regions included in Insurance data due to what was surveyed in the study. Due to this, I will be only including those regions for the google data so the comparison is equal. This excludes certain states like Alaska who are in the far north region. They will be labeled with an NA and then ommitted from the dataset.

```{r}
StateGoogleData <-
  gatheredData %>% 
  group_by(dma, condition) %>% 
  summarise (total = sum(value))

#head(StateGoogleData, 6)

southwest <- c('AZ','CA','NM','NV','OK','TX')
southeast <- c('AL','AR','DE','FL','GA','KY','LA','MD','DC','MS','MC','SC')
northwest <- c('CA', 'CO', 'ID', 'MT', 'ND', 'NE', 'NV', 'OR', 'SD', 'UT', 'WA', 'WY')
northeast <- c('CT','IA','IL','IN','KS','MA','ME','MI','MN','MO','NH','NJ','NY','OH','PA','RI','SD','VA','VT','WI', 'WV')

RegionalGoogleData <-
  StateGoogleData %>% 
  mutate(region = ifelse(dma %in% southwest, "southwest",
                                     ifelse(dma %in% southeast, "southeast",
                                            ifelse(dma %in% northwest, "northwest",
                                                   ifelse(dma %in% northeast, "northeast", NA)))))

RegionalGoogleData <- na.omit(RegionalGoogleData)
head(RegionalGoogleData)
```


- Here is some analysis of the 2017 google data.

```{r}
# searches by state



#searches by region
RegionSearches <-
  ggplot(data=RegionalGoogleData,aes(x=reorder(condition,total),y=total ,fill=condition))+geom_bar(stat='identity',position='stack', width=.9) + theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + facet_wrap(~region,ncol=2) 

RegionSearches
```






















